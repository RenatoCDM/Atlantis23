{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2596736f-ef7d-4e5d-99c3-1532710db7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Developed by Renato Cezar, based on the script \"getting_started.ipynb\" supplied by THE FORAGE\n",
    "### to perform an on the job training for BRITISH AIRWAYS\n",
    "### Last modification: May 12th 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5903490-d2eb-4462-a2c2-deba60363c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c6e5e8-a1e2-47e4-be44-5ae78ab1a616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n"
     ]
    },
    {
     "ename": "ProxyError",
     "evalue": "HTTPSConnectionPool(host='www.airlinequality.com', port=443): Max retries exceeded with url: /airline-reviews/british-airways/page/1/?sortby=post_date%3ADesc&pagesize=100 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden')))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/urllib3/connectionpool.py:700\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_new_proxy_conn \u001b[38;5;129;01mand\u001b[39;00m http_tunnel_required:\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/urllib3/connectionpool.py:994\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    992\u001b[0m     conn\u001b[38;5;241m.\u001b[39mtls_in_tls_required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/urllib3/connection.py:369\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# Calls self._set_hostport(), so self.host is\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# self._tunnel_host below.\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Mark this connection as not reusable\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/http/client.py:930\u001b[0m, in \u001b[0;36mHTTPConnection._tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 930\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTunnel connection failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: Tunnel connection failed: 403 Forbidden",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/urllib3/connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    783\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 785\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.airlinequality.com', port=443): Max retries exceeded with url: /airline-reviews/british-airways/page/1/?sortby=post_date%3ADesc&pagesize=100 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/page/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/?sortby=post_date%3ADesc&pagesize=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Collect HTML data from this page\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Pre Parse content\u001b[39;00m\n\u001b[1;32m     22\u001b[0m content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages/requests/adapters.py:513\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _ProxyError):\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mProxyError\u001b[0m: HTTPSConnectionPool(host='www.airlinequality.com', port=443): Max retries exceeded with url: /airline-reviews/british-airways/page/1/?sortby=post_date%3ADesc&pagesize=100 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden')))"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "# Set the number of pages to be scraped\n",
    "pages = 20\n",
    "# Set the number of registers per page\n",
    "page_size = 100\n",
    "\n",
    "parsed_content = []\n",
    "lists_survey = []\n",
    "\n",
    "# Loop to scrap content from each page:\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Pre Parse content\n",
    "    content = response.content\n",
    "    pre_parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Split the articles from Pre Parsed Content and store them in a list of lists\n",
    "    #parsed_content = pre_parsed_content.find_all(\"article\", {\"itemprop\": \"review\"})\n",
    "    for article in pre_parsed_content.find_all(\"article\", {\"itemprop\": \"review\"}):\n",
    "        parsed_content.append(article)\n",
    "    \n",
    "    # Print the progress\n",
    "    print(f\"   ---> {len(parsed_content)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63cff5-e067-4fd0-ad78-e2e9afd13b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section to transform the data mass in parsed_content in a handsome dataset to be analyzed \n",
    "lists_survey = []\n",
    "for i in range(0, len(parsed_content) - 1):\n",
    "    # Gathering and organizing the data from the scrap\n",
    "    # Date of survey\n",
    "    date = parsed_content[i].find(\"time\").contents[0]\n",
    "    # Subject given by the surveyed\n",
    "    subject = parsed_content[i].find(attrs={\"class\": \"text_header\"}).contents[0]\n",
    "    # Name of the surveyed \n",
    "    name = parsed_content[i].find(attrs={\"itemprop\": \"name\"}).contents[0]\n",
    "    # Country of the surveyed\n",
    "    country = parsed_content[i].find(\"h3\").contents[2]\n",
    "    # Verification status of the surveyed trip \n",
    "    try:\n",
    "        trip = parsed_content[i].find(\"em\").contents[0]\n",
    "    except AttributeError:\n",
    "        trip = \"NotAvailable\" \n",
    "    # Commentary of the surveyed\n",
    "    try:\n",
    "        commentary = parsed_content[i].find(attrs={\"class\": \"text_content\"}).contents[2]\n",
    "    except IndexError:\n",
    "        try:\n",
    "            commentary = parsed_content[i].find(attrs={\"class\": \"text_content\"}).contents[1]\n",
    "        except IndexError:\n",
    "            commentary = parsed_content[i].find(attrs={\"class\": \"text_content\"}).contents[0]\n",
    "    # Aircraft model\n",
    "    try:\n",
    "        aircraft = parsed_content[i].find(attrs={\"class\": \"review-rating-header aircraft\"}).parent\n",
    "        aircraft = aircraft.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        aircraft = \"NotInformed\"\n",
    "    # Type of traveller\n",
    "    try:\n",
    "        type_traveller = parsed_content[i].find(attrs={\"class\": \"review-rating-header type_of_traveller\"}).parent\n",
    "        type_traveller = type_traveller.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        seat_type = \"NotInformed\"\n",
    "    # Seat/cabin type purchased\n",
    "    try:\n",
    "        seat_type = parsed_content[i].find(attrs={\"class\": \"review-rating-header cabin_flown\"}).parent\n",
    "        seat_type =  seat_type.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        seat_type = \"NotInformed\"\n",
    "    # Flight route\n",
    "    try:\n",
    "        route = parsed_content[i].find(attrs={\"class\": \"review-rating-header route\"}).parent\n",
    "        route = route.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        route = \"NotInformed\"\n",
    "    # Date flown\n",
    "    try:\n",
    "        date_flown = parsed_content[i].find(attrs={\"class\": \"review-rating-header date_flown\"}).parent\n",
    "        date_flown = date_flown.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        date_flown = \"NotInformed\"\n",
    "    # Star ratings (coded to take only the maximum star rating)\n",
    "    # Seat Comfort\n",
    "    try:\n",
    "        stars_seat_comfort = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header seat_comfort\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_seat_comfort = \"NotEvaluated\"\n",
    "    # Cabin Staff Service\n",
    "    try:      \n",
    "        stars_cabin_staff_service = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header cabin_staff_service\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_cabin_staff_service = \"NotEvaluated\"    \n",
    "    # Food and Beverage\n",
    "    try:\n",
    "        stars_food_beverage = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header food_and_beverages\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_food_beverage = \"NotEvaluated\"\n",
    "    # Inflight Entertainment\n",
    "    try:\n",
    "        stars_inflight_entertainment = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header inflight_entertainment\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_inflight_entertainment = \"NotEvaluated\"\n",
    "    # Ground Services\n",
    "    try:\n",
    "        stars_ground_services = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header ground_service\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_ground_services = \"NotEvaluated\"\n",
    "    # WiFi and Connectivity\n",
    "    try:\n",
    "        stars_wifi_connectivity = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header wifi_and_connectivity\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_wifi_connectivity = \"NotEvaluated\"    \n",
    "    # Value for Money\n",
    "    try:\n",
    "        stars_value_money = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header value_for_money\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_value_money = \"NotEvaluated\"\n",
    "    # Recomended\n",
    "    recommended = parsed_content[i].find(attrs={\"class\": \"review-rating-header recommended\"}).parent\n",
    "    recommended = recommended.find(attrs={\"class\": re.compile(\"review-value rating-*\")}).contents[0]\n",
    "\n",
    "    # Storing the organized data as list in a set of lists\n",
    "    lists_survey.append([date, subject, name, country, trip, commentary, aircraft, type_traveller, seat_type, route, date_flown, \n",
    "                    stars_seat_comfort, stars_cabin_staff_service, stars_food_beverage, stars_inflight_entertainment, \n",
    "                    stars_ground_services, stars_wifi_connectivity, stars_value_money, recommended])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa578405-e946-4d64-a6f9-1adc341421cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating the text to remove any unnecessary chars (e.g: \"|\", \"(\" and \")\") from Subject_Surveyer, Country_Surveyer and Commentary_Surveyer\n",
    "# and formating the date in Survey_Date to the pattern \"DD/MM/YYYY\"\n",
    "for i in range(0, len(lists_survey)):\n",
    "    lists_survey[i][1] = lists_survey[i][1].lstrip('\"').rstrip('\"')\n",
    "    lists_survey[i][3] = lists_survey[i][3].lstrip(\"(\").rstrip(\")\")\n",
    "    lists_survey[i][5] = lists_survey[i][5].replace(\"|\", \"\")\n",
    "    \n",
    "    lists_survey[i][0] = parse(lists_survey[i][0]).strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f9c32-6613-4832-93bf-819d13a1ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and populating the data frame with the se of lists to handle the survey data in a tabular way\n",
    "dataframe_survey = pd.DataFrame(lists_survey, columns=['Survey_Date', \"Subject_Surveyer\", \"Name_Surveyer\", \"Country_Surveyer\", \n",
    "                                 \"Trip_Verification\", \"Commentary_Surveyer\", \"Aircraft\", \"Traveller_Type\", \n",
    "                                 \"Seat_Type\", \"Route\", \"Date_Flown\", \"Seat_Comfort\", \"Cabin_Services\", \n",
    "                                 \"Food_Beverage\", \"Inflight_Entertainment\", \"Ground_Services\", \"WiFi_Connectivity\", \n",
    "                                 \"Value_Money\",\"Recommended\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae6f41-81cb-4265-8bc9-8718339ae56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71705b74-13fd-41ad-99bd-a4f92614202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data set as an Excel file\n",
    "dataframe_survey.to_excel(\"BA_reviews-\" + datetime.datetime.now().strftime(\"%d%b%Y_%H%M%S\") + \".xlsx\", sheet_name=\"reviews\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08a407-f7b0-45c3-ae4b-70be52ec3d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
