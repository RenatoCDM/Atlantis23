{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2596736f-ef7d-4e5d-99c3-1532710db7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Developed by Renato Cezar, based on the script \"getting_started.ipynb\" supplied by THE FORAGE\n",
    "### to perform an on the job training for BRITISH AIRWAYS\n",
    "### Last modification: May 13th 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5903490-d2eb-4462-a2c2-deba60363c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # For web page scrapping\n",
    "from bs4 import BeautifulSoup # For HTML parsing and handling\n",
    "import pandas as pd # For data frames and data series\n",
    "import re as re # For RegEx\n",
    "import datetime # For date and time handling\n",
    "from dateutil.parser import parse # For date and time parsing \n",
    "import nbimporter # To use outter python codes and notebooks\n",
    "import matplotlib.pyplot as plt # To generate plots and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c6e5e8-a1e2-47e4-be44-5ae78ab1a616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "# Set the number of pages to be scraped\n",
    "pages = 20\n",
    "# Set the number of registers per page\n",
    "page_size = 100\n",
    "\n",
    "parsed_content = []\n",
    "lists_survey = []\n",
    "\n",
    "# Loop to scrap content from each page:\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Pre Parse content\n",
    "    content = response.content\n",
    "    pre_parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Split the articles from Pre Parsed Content and store them in a list of lists\n",
    "    for article in pre_parsed_content.find_all(\"article\", {\"itemprop\": \"review\"}):\n",
    "        parsed_content.append(article)\n",
    "    \n",
    "    # Print the progress\n",
    "    print(f\"   ---> {len(parsed_content)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d126e89e-5574-467e-a9d5-9f1180f8cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section to transform the data mass in parsed_content in a handsome dataset to be analyzed \n",
    "lists_survey = []\n",
    "for i in range(0, len(parsed_content) - 1):\n",
    "    # Gathering and organizing the data from the scrap\n",
    "    # Date of survey\n",
    "    date = parsed_content[i].find(\"time\").contents[0]\n",
    "    # Subject given by the surveyed\n",
    "    subject = parsed_content[i].find(attrs={\"class\": \"text_header\"}).contents[0]\n",
    "    # Name of the surveyed \n",
    "    name = parsed_content[i].find(attrs={\"itemprop\": \"name\"}).contents[0]\n",
    "    # Country of the surveyed\n",
    "    country = parsed_content[i].find(\"h3\").contents[2]\n",
    "    # Verification status of the surveyed trip \n",
    "    try:\n",
    "        trip_verification = parsed_content[i].find(\"em\").contents[0]\n",
    "    except AttributeError:\n",
    "        trip_verification = \"NotAvailable\" \n",
    "    # Commentary of the surveyed\n",
    "    try:\n",
    "        commentary = parsed_content[i].find(attrs={\"class\": \"text_content\"}).contents[2]\n",
    "    except IndexError:\n",
    "        try:\n",
    "            commentary = parsed_content[i].find(attrs={\"class\": \"text_content\"}).contents[1]\n",
    "        except IndexError:\n",
    "            commentary = parsed_content[i].find(attrs={\"class\": \"text_content\"}).contents[0]\n",
    "    # Aircraft model\n",
    "    try:\n",
    "        aircraft = parsed_content[i].find(attrs={\"class\": \"review-rating-header aircraft\"}).parent\n",
    "        aircraft = aircraft.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        aircraft = \"NotInformed\"\n",
    "    # Type of traveller\n",
    "    try:\n",
    "        type_traveller = parsed_content[i].find(attrs={\"class\": \"review-rating-header type_of_traveller\"}).parent\n",
    "        type_traveller = type_traveller.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        seat_type = \"NotInformed\"\n",
    "    # Seat/cabin type purchased\n",
    "    try:\n",
    "        seat_type = parsed_content[i].find(attrs={\"class\": \"review-rating-header cabin_flown\"}).parent\n",
    "        seat_type =  seat_type.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        seat_type = \"NotInformed\"\n",
    "    # Flight route\n",
    "    try:\n",
    "        route = parsed_content[i].find(attrs={\"class\": \"review-rating-header route\"}).parent\n",
    "        route = route.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "        # Splitting the trip to catch separately \"From\", \"To\" and \"Via\"\n",
    "        # First, verifity if theres is a \"to\"\n",
    "        to = route.find(' to ') # if there is no \"to\", it will no be possible to securely splity this trip\n",
    "        if to == -1: # So take all the string as \"from\"\n",
    "            route_from = route\n",
    "            route_to = \"NotApplicable\"\n",
    "            route_via = \"NotApplicable\"\n",
    "        else: # In case of existing a \"to\", check if there is a \"via\"\n",
    "            via = route.find(' via ') # if there is no \"via\", just take the \"from\" and \"to\"\n",
    "            if via == -1:\n",
    "                route_from = route.split(\" to \")[0]\n",
    "                route_to = route.split(\" to \")[1]\n",
    "                route_via = \"NotApplicable\"\n",
    "            else: # if there is a via, so take the \"from\", \"to\" and \"via\"\n",
    "                route_from = route.split(\" to \")[0]\n",
    "                route_to_via = route.split(\" to \")[1]\n",
    "                route_to = route_to_via.split(\" via \")[0]\n",
    "                route_via = route.split(\" via \")[1]\n",
    "    except AttributeError:\n",
    "        route_from = \"NotInformed\"\n",
    "        route_to = \"NotInformed\"\n",
    "        route_via = \"NotInformed\"\n",
    "    # Date flown\n",
    "    try:\n",
    "        date_flown = parsed_content[i].find(attrs={\"class\": \"review-rating-header date_flown\"}).parent\n",
    "        date_flown = date_flown.find(attrs={\"class\": \"review-value\"}).contents[0]\n",
    "    except AttributeError:\n",
    "        date_flown = \"NotInformed\"\n",
    "    # Star ratings (coded to take only the maximum star rating)\n",
    "    # Seat Comfort\n",
    "    try:\n",
    "        stars_seat_comfort = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header seat_comfort\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_seat_comfort = \"NotEvaluated\"\n",
    "    # Cabin Staff Service\n",
    "    try:      \n",
    "        stars_cabin_staff_service = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header cabin_staff_service\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_cabin_staff_service = \"NotEvaluated\"    \n",
    "    # Food and Beverage\n",
    "    try:\n",
    "        stars_food_beverage = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header food_and_beverages\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_food_beverage = \"NotEvaluated\"\n",
    "    # Inflight Entertainment\n",
    "    try:\n",
    "        stars_inflight_entertainment = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header inflight_entertainment\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_inflight_entertainment = \"NotEvaluated\"\n",
    "    # Ground Services\n",
    "    try:\n",
    "        stars_ground_services = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header ground_service\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_ground_services = \"NotEvaluated\"\n",
    "    # WiFi and Connectivity\n",
    "    try:\n",
    "        stars_wifi_connectivity = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header wifi_and_connectivity\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_wifi_connectivity = \"NotEvaluated\"    \n",
    "    # Value for Money\n",
    "    try:\n",
    "        stars_value_money = len((parsed_content[i].find(attrs={\"class\": \"review-rating-header value_for_money\"}).parent).find_all(\"span\", {\"class\": \"star fill\"}))\n",
    "    except AttributeError:\n",
    "        stars_value_money = \"NotEvaluated\"\n",
    "    # Recomended\n",
    "    recommended = parsed_content[i].find(attrs={\"class\": \"review-rating-header recommended\"}).parent\n",
    "    recommended = recommended.find(attrs={\"class\": re.compile(\"review-value rating-*\")}).contents[0]\n",
    "\n",
    "    # Storing the organized data as list in a set of lists\n",
    "    lists_survey.append([date, subject, name, country, trip_verification, commentary, aircraft, type_traveller, \n",
    "                         seat_type, route_from, route_to, route_via, date_flown, stars_seat_comfort, \n",
    "                         stars_cabin_staff_service, stars_food_beverage, stars_inflight_entertainment, \n",
    "                         stars_ground_services, stars_wifi_connectivity, stars_value_money, recommended])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa578405-e946-4d64-a6f9-1adc341421cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Treating the text to remove any unnecessary chars (e.g: \"|\", \"(\" and \")\") from Subject_Surveyer, Country_Surveyer and Commentary_Surveyer,\n",
    "# formating the date in Survey_Date to the pattern \"DD/MM/YYYY\" and Date_Flown to \"MM/YYYY\"\n",
    "for i in range(0, len(lists_survey)):\n",
    "    #lists_survey[i][1] = lists_survey[i][1].replace('\"', \"\")\n",
    "    lists_survey[i][3] = lists_survey[i][3][lists_survey[i][3].find('(')+1 : lists_survey[i][3].find(')')]\n",
    "    lists_survey[i][5] = lists_survey[i][5].replace(\"|\", \"\")\n",
    "    \n",
    "    lists_survey[i][0] = parse(lists_survey[i][0]).strftime('%d/%m/%Y')\n",
    "    lists_survey[i][12] = parse(lists_survey[i][12]).strftime('%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a08f81b-ee49-47a1-8bcb-638266b56f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and uniformizing airport names (focusing in the London)\n",
    "for i in range(0, len(lists_survey)):\n",
    "    # Route_From\n",
    "    lists_survey[i][9] = lists_survey[i][9].lstrip('\"').rstrip('\"')\n",
    "    lists_survey[i][9] = lists_survey[i][9].lstrip(' ').rstrip(' ')\n",
    "    lists_survey[i][9] = lists_survey[i][9].lstrip(',').rstrip(',')\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London Heathrow\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London LHR\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London LGW\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London LCY\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London City\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London Cuty\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London-Heathrow\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London UK (Heathrow)\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London Heaathrow\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"London Gatwick\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"Gatwick\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"Heathrow\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"LHR\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"LGW\", \"London\")\n",
    "    lists_survey[i][9] = lists_survey[i][9].replace(\"LCY\", \"London\")\n",
    "    # Route_To\n",
    "    lists_survey[i][10] = lists_survey[i][10].lstrip('\"').rstrip('\"')\n",
    "    lists_survey[i][10] = lists_survey[i][10].lstrip(' ').rstrip(' ')\n",
    "    lists_survey[i][10] = lists_survey[i][10].lstrip(',').rstrip(',')\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London Heathrow\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London LHR\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London LGW\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London LCY\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London City\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London Cuty\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London-Heathrow\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London UK (Heathrow)\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London Heaathrow\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"London Gatwick\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"Gatwick\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"Heathrow\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"LHR\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"LGW\", \"London\")\n",
    "    lists_survey[i][10] = lists_survey[i][10].replace(\"LCY\", \"London\")\n",
    "    # Route_Via\n",
    "    lists_survey[i][11] = lists_survey[i][11].lstrip('\"').rstrip('\"')\n",
    "    lists_survey[i][11] = lists_survey[i][11].lstrip(' ').rstrip(' ')\n",
    "    lists_survey[i][11] = lists_survey[i][11].lstrip(',').rstrip(',')\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London Heathrow\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London LHR\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London LGW\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London LCY\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London City\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London Cuty\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London-Heathrow\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London UK (Heathrow)\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London Heaathrow\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"London Gatwick\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"Gatwick\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"Heathrow\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"LHR\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"LGW\", \"London\")\n",
    "    lists_survey[i][11] = lists_survey[i][11].replace(\"LCY\", \"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914f9c32-6613-4832-93bf-819d13a1ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and populating the data frame with the se of lists to handle the survey data in a tabular way\n",
    "dataframe_survey = pd.DataFrame(lists_survey, columns=[\"Survey_Date\", \"Subject_Surveyer\", \"Name_Surveyer\", \"Country_Surveyer\", \n",
    "                                 \"Trip_Verification\", \"Commentary_Surveyer\", \"Aircraft\", \"Traveller_Type\", \n",
    "                                 \"Seat_Type\", \"Route_From\", \"Route_To\", \"Route_Via\", \"Date_Flown\", \"Seat_Comfort\", \n",
    "                                 \"Cabin_Services\", \"Food_Beverage\", \"Inflight_Entertainment\", \"Ground_Services\", \n",
    "                                 \"WiFi_Connectivity\", \"Value_Money\",\"Recommended\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e08a407-f7b0-45c3-ae4b-70be52ec3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the python helper script BA-Helper to use auxiliary functions\n",
    "%run -i BA-Helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f10c40-7388-4257-aebc-806f5bef90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renat\\AppData\\Local\\Temp\\ipykernel_9296\\945477436.py:4: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  dataframe_survey = dataframe_survey.replace((dataframe_airport[['IATA', 'Airport_Name']].set_index('IATA').T.to_dict('records'))[0])\n"
     ]
    }
   ],
   "source": [
    "# Call the function iata_converter, from BA-Helper, to get IATA, ICAO and airport names\n",
    "dataframe_airport = iata_converter()\n",
    "# Replace IATA codes in the client survey data frame to the airport name\n",
    "dataframe_survey = dataframe_survey.replace((dataframe_airport[['IATA', 'Airport_Name']].set_index('IATA').T.to_dict('records'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "091b9561-58de-4240-8479-f79febfc333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data set as an Excel file\n",
    "dataframe_survey.to_excel(\"BA_reviews-\" + datetime.datetime.now().strftime(\"%d%b%Y_%H%M%S\") + \".xlsx\", sheet_name=\"reviews\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b07533-bb7e-436a-a9bf-f649bdfbafc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that all data is nice and clean it's time to perform some basic statistics \n",
    "\n",
    "# Starting with getting the oldest and the earliest survey data date\n",
    "# Transforming the date into an ordinal and building a list to take the higher and the \n",
    "# the smaller value, which are correspondant to the earliest and the oldest dates \n",
    "lists_dates = []\n",
    "for i in range(0, len(dataframe_survey)):\n",
    "    normal_date = dataframe_survey['Survey_Date'][i]\n",
    "    ordinal_date = int(datetime.datetime.strptime(dataframe_survey['Survey_Date'][i], '%d/%m/%Y').toordinal())\n",
    "    lists_dates.append([ordinal_date, normal_date])\n",
    "    \n",
    "dataframe_dates = pd.DataFrame(lists_dates, columns=[\"Ordinal_Date\", \"Normal_Date\"])\n",
    "list_earlier_oldest_date = [datetime.datetime.fromordinal(max(dataframe_dates[\"Ordinal_Date\"])).strftime(\"%d/%m/%Y\"), datetime.datetime.fromordinal(min(dataframe_dates[\"Ordinal_Date\"])).strftime(\"%d/%m/%Y\")]\n",
    "serie_survey_dates = pd.Series(list_earlier_oldest_date, index = [\"Earliest survey\", \"Oldest survey\"], name = \"Earlier_Oldest_Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1a57a6-674b-4c1d-abad-846f40f36993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now taking some data grouping and counting\n",
    "group_count_country_surveyer = dataframe_survey.groupby(\"Country_Surveyer\")[\"Country_Surveyer\"].count().sort_values(ascending = False)\n",
    "group_count_trip_verification = dataframe_survey.groupby(\"Trip_Verification\")[\"Trip_Verification\"].count().sort_values(ascending = False)\n",
    "group_count_aircraft = dataframe_survey.groupby(\"Aircraft\")[\"Aircraft\"].count().sort_values(ascending = False)\n",
    "group_count_traveller_type = dataframe_survey.groupby(\"Traveller_Type\")[\"Traveller_Type\"].count().sort_values(ascending = False)\n",
    "group_count_seat_type = dataframe_survey.groupby(\"Seat_Type\")[\"Seat_Type\"].count().sort_values(ascending = False)\n",
    "group_count_route_from = dataframe_survey.groupby(\"Route_From\")[\"Route_From\"].count().sort_values(ascending = False)\n",
    "group_count_route_to = dataframe_survey.groupby(\"Route_To\")[\"Route_To\"].count().sort_values(ascending = False)\n",
    "group_count_route_via = dataframe_survey.groupby(\"Route_Via\")[\"Route_Via\"].count().sort_values(ascending = False)\n",
    "group_count_date_flown = dataframe_survey.groupby(\"Date_Flown\")[\"Date_Flown\"].count().sort_values(ascending = False)\n",
    "group_count_recommended = dataframe_survey.groupby(\"Recommended\")[\"Recommended\"].count().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e6be83-a3b5-47a6-aef0-8f67323c5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest survey    13/05/2023\n",
      "Oldest survey      13/08/2016\n",
      "Name: Earlier_Oldest_Date, dtype: object\n",
      "Country_Surveyer\n",
      "United Kingdom    1231\n",
      "United States      240\n",
      "Canada              64\n",
      "Australia           63\n",
      "Germany             42\n",
      "                  ... \n",
      "Philippines          1\n",
      "Panama               1\n",
      "Israel               1\n",
      "Jordan               1\n",
      "Vietnam              1\n",
      "Name: Country_Surveyer, Length: 64, dtype: int64\n",
      "Trip_Verification\n",
      "Trip Verified    1035\n",
      "NotAvailable      771\n",
      "Not Verified      193\n",
      "Name: Trip_Verification, dtype: int64\n",
      "Aircraft\n",
      "NotInformed       739\n",
      "A320              247\n",
      "Boeing 777        169\n",
      "A380              117\n",
      "Boeing 747-400    100\n",
      "                 ... \n",
      "A320-233            1\n",
      "Boeing 744          1\n",
      "787                 1\n",
      "Boeing 737 800      1\n",
      "Various             1\n",
      "Name: Aircraft, Length: 144, dtype: int64\n",
      "Traveller_Type\n",
      "Couple Leisure    657\n",
      "Solo Leisure      608\n",
      "Business          462\n",
      "Family Leisure    272\n",
      "Name: Traveller_Type, dtype: int64\n",
      "Seat_Type\n",
      "Economy Class      1110\n",
      "Business Class      604\n",
      "Premium Economy     188\n",
      "First Class          97\n",
      "Name: Seat_Type, dtype: int64\n",
      "Route_From\n",
      "London          922\n",
      "Johannesburg     26\n",
      "Los Angeles      25\n",
      "Miami            22\n",
      "Cape Town        21\n",
      "               ... \n",
      "Bologna           1\n",
      "Leeds             1\n",
      "Boryspil          1\n",
      "Brindisi          1\n",
      "doha              1\n",
      "Name: Route_From, Length: 257, dtype: int64\n",
      "Route_To\n",
      "London                          744\n",
      "Cape Town                        34\n",
      "Hong Kong                        26\n",
      "Johannesburg                     23\n",
      "Los Angeles                      22\n",
      "                               ... \n",
      "Franz Josef Strauss               1\n",
      "Genoa                             1\n",
      "George Bush Intercontinental      1\n",
      "Grenada                           1\n",
      "san Francisco                     1\n",
      "Name: Route_To, Length: 299, dtype: int64\n",
      "Route_Via\n",
      "NotApplicable            1673\n",
      "London                    284\n",
      "Singapore                  13\n",
      "Singapore Changi            3\n",
      "NotInformed                 3\n",
      "Barajas                     1\n",
      "Los Angeles                 1\n",
      "Toronto / London            1\n",
      "Sydney                      1\n",
      "Suvarnabhumi                1\n",
      "St. Lucia                   1\n",
      "Singapore / London          1\n",
      "OR Tambo                    1\n",
      "Miami / Madrid              1\n",
      "London/London               1\n",
      "Barcelona                   1\n",
      "London / Singapore          1\n",
      "London / Seattle            1\n",
      "London / Johannesburg       1\n",
      "LAD & ABV                   1\n",
      "Johannesburg / London       1\n",
      "Geneva                      1\n",
      "Dublin                      1\n",
      "Doha                        1\n",
      "Copenhagen                  1\n",
      "Chicago / London            1\n",
      "Chicago                     1\n",
      "london                      1\n",
      "Name: Route_Via, dtype: int64\n",
      "Date_Flown\n",
      "04/2017    65\n",
      "01/2017    60\n",
      "11/2016    58\n",
      "10/2016    57\n",
      "06/2017    56\n",
      "           ..\n",
      "06/2016     1\n",
      "04/2016     1\n",
      "03/2016     1\n",
      "06/2020     1\n",
      "01/2016     1\n",
      "Name: Date_Flown, Length: 87, dtype: int64\n",
      "Recommended\n",
      "no     1346\n",
      "yes     653\n",
      "Name: Recommended, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(serie_survey_dates)\n",
    "print(group_count_country_surveyer)\n",
    "print(group_count_trip_verification)\n",
    "print(group_count_aircraft)\n",
    "print(group_count_traveller_type)\n",
    "print(group_count_seat_type)\n",
    "print(group_count_route_from)\n",
    "print(group_count_route_to)\n",
    "print(group_count_route_via)\n",
    "print(group_count_date_flown)\n",
    "print(group_count_recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f96b0-af0f-4f52-85d0-cb221061879b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
